{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 출처 : 머신러닝 교과서 with 파이썬\n",
    "\n",
    "- 퍼셉트론은 두 클래스가 선형적으로 구분되고 학습률이 충분히 작을 때만 수렴이 보장 됨.\n",
    "- 두 클래스를 선형 결정 경계로 나눌 수 없다면 훈련 데이터셋을 반복할 최대횟수 (epoch:에포크)와 분류 허용 오차를 지정\n",
    "- 그렇지 않으면 퍼셉트론은 가중치 업데이트를 멈추지 않음\n",
    "\n",
    "## 과제1. 아래의 코드에 주석을 달고 각 결과물이 무엇을 보이고 있는지 코멘트 남겨주세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    " \n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "       \n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "       \n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris data에서 퍼셉트론 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "        'machine-learning-databases/iris/iris.data', header=None)\n",
    "\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# setosa와 versicolor를 선택합니다\n",
    "y = df.iloc[0:100, 4].values\n",
    "# setosa일 경우 -1, 아니면(versicolor) 1\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "\n",
    "# 꽃받침 길이와 꽃잎 길이를 추출합니다\n",
    "X = df.iloc[0:100, [0, 2]].values\n",
    "\n",
    "# 산점도를 그립니다\n",
    "plt.scatter(X[:50, 0], X[:50, 1],\n",
    "            color='red', marker='o', label='setosa')\n",
    "plt.scatter(X[50:100, 0], X[50:100, 1],\n",
    "            color='blue', marker='x', label='versicolor')\n",
    "\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppn = Perceptron(eta=0.1, n_iter=10)\n",
    "\n",
    "ppn.fit(X, y)\n",
    "print(ppn.errors_)\n",
    "\n",
    "plt.plot(range(1, len(ppn.errors_) + 1), ppn.errors_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of errors')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # 마커와 컬러맵을 설정합니다\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # 결정 경계를 그립니다\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # 샘플의 산점도를 그립니다\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X, y, classifier=ppn)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets  #만약  datasets가 없다는 오류 메세지가 뜬다면 위에서 불러온 방법으로 로딩\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()  \n",
    "\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "print('class label:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label count of y:', np.bincount(y))\n",
    "print('label count of y_train:', np.bincount(y_train))\n",
    "print('label count of y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(max_iter=40, eta0=0.1, tol=1e-3, random_state=1)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('The number of misclassified sample : %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # 마커와 컬러맵을 설정합니다.\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # 결정 경계를 그립니다.\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # 테스트 샘플을 부각하여 그립니다.\n",
    "    if test_idx:\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    facecolors='none',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "plot_decision_regions(X=X_combined_std, y=y_combined,\n",
    "                      classifier=ppn, test_idx=range(105, 150))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "- 여기를 참고하셔서 수업시간에 배운 내용을 상기시켜보면 이 사이트의 내용이 이해가 되실 것이라 생각됩니다. \n",
    "- 이곳에서 MLPClassifier에 주어지는 parameter에 대해 이해하시기 바랍니다.\n",
    "- https://tensorflow.blog/%ed%8c%8c%ec%9d%b4%ec%8d%ac-%eb%a8%b8%ec%8b%a0%eb%9f%ac%eb%8b%9d/2-3-8-%ec%8b%a0%ea%b2%bd%eb%a7%9d%eb%94%a5%eb%9f%ac%eb%8b%9d/#neural-model\n",
    "- 위 사이트가 introduction to machine learning with python 의 번역본이고 교재의 코드입니다.\n",
    "\n",
    "## 과제2.  아래의 코드에 주석을 달고 결과물이 무엇을 의미하는지 교재를 보고 요약해서 코멘트하기\n",
    "\n",
    "- 반복되는 코드의 주석을 모두 달아줄 필요는 없습니다. 변경 된 부분만! 스스로에게 도움이 되는 과제가 되세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mglearn\n",
    "\n",
    "X,y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, stratify=y, random_state=42)\n",
    "\n",
    "mlp=MLPClassifier(solver='lbfgs', random_state=0).fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:,0], X_train[:,1], y_train)\n",
    "plt.xlabel('zero')\n",
    "plt.ylabel('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', random_state=0, hidden_layer_sizes=[10])\n",
    "mlp.fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel('zero')\n",
    "plt.ylabel('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "for axx, n_hidden_nodes in zip(axes, [10, 100]):\n",
    "    for ax, alpha in zip(axx, [0.0001, 0.01, 0.1, 1]):\n",
    "        mlp = MLPClassifier(solver='lbfgs', random_state=0,\n",
    "                            hidden_layer_sizes=[n_hidden_nodes, n_hidden_nodes],\n",
    "                            alpha=alpha)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3, ax=ax)\n",
    "        mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train, ax=ax)\n",
    "        ax.set_title(\"n_hidden=[{}, {}]\\nalpha={:.4f}\".format(\n",
    "                      n_hidden_nodes, n_hidden_nodes, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    mlp = MLPClassifier(solver='lbfgs', random_state=i,\n",
    "                        hidden_layer_sizes=[100, 100])\n",
    "    mlp.fit(X_train, y_train)\n",
    "    mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3, ax=ax)\n",
    "    mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max:\\n{}\".format(cancer.data.max(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"train accuracy: {:.2f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"test accuracy: {:.2f}\".format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트 각 특성의 평균을 계산합니다.\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "# 훈련 세트 각 특성의 표준 편차를 계산합니다.\n",
    "std_on_train = X_train.std(axis=0)\n",
    "\n",
    "# 데이터에서 평균을 빼고 표준 편차로 나누면\n",
    "# 평균 0, 표준 편차 1인 데이터로 변환됩니다.\n",
    "X_train_scaled = (X_train - mean_on_train) / std_on_train\n",
    "# (훈련 데이터의 평균과 표준 편차를 이용해) 같은 변환을 테스트 세트에도 합니다.\n",
    "X_test_scaled = (X_test - mean_on_train) / std_on_train\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"train accuracy: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"test accuracy: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"train accuracy: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"test accuracy: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, alpha=1, random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"train accuracy: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"test accuracy: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')\n",
    "plt.yticks(range(30), cancer.feature_names)\n",
    "plt.xlabel(\"hidden unit\")\n",
    "plt.ylabel(\"input\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 3.  breast cancer에 대해 앞서 제출했던 분류 모델과 신경망까지 모두 사용해서 정확도를 표준화 전후를 포함해서 비교해주세요. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
